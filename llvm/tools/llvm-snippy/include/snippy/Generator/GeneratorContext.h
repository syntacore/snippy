//===-- GeneratorContext.h -------  -----------------------------*- C++ -*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//

#pragma once

#include "snippy/Config/CallGraphLayout.h"
#include "snippy/Config/FPUSettings.h"
#include "snippy/Config/MemoryScheme.h"
#include "snippy/Config/OpcodeHistogram.h"
#include "snippy/Generator/BurstMode.h"
#include "snippy/Generator/GeneratorSettings.h"
#include "snippy/Generator/GlobalsPool.h"
#include "snippy/Generator/ImmediateHistogram.h"
#include "snippy/Generator/LLVMState.h"
#include "snippy/Generator/Linker.h"
#include "snippy/Generator/MemoryManager.h"
#include "snippy/Generator/RegisterGenerator.h"
#include "snippy/Generator/RegisterPool.h"
#include "snippy/Generator/SimRunner.h"
#include "snippy/Generator/SnippyModule.h"
#include "snippy/Generator/TopMemAccSampler.h"
#include "snippy/Target/Target.h"

#include "llvm/CodeGen/MachineModuleInfo.h"
#include "llvm/Support/Debug.h"
namespace llvm {
class MachineModuleInfo;
class TargetSubtargetInfo;
} // namespace llvm

namespace llvm {
namespace snippy {

class ImmediateHistogram;
class InitialReg;
class Interpreter;
class LLVMState;
class MemoryScheme;
class OpcodeCache;
class RootRegPoolWrapper;
struct TargetGenContextInterface;
class Linker;
class GlobalsPool;
struct IRegisterState;

enum class GenerationMode {
  // Ignore Size requirements, only num Instrs
  NumInstrs,
  // Ignore num instrs, try to meet size requirements
  Size,
  // Try to satisfy both num instrs and size requirements
  Mixed
};

enum class LoopType { UpCount, DownCount };

using BurstGroupAccessDesc = std::vector<AddressInfo>;
using PlainAccessesType = std::vector<AccessAddress>;
using BurstGroupAccessesType = std::vector<BurstGroupAccessDesc>;

class GeneratorContext {
public:
  struct LoopGenerationInfo {
    Register CounterReg;
    unsigned NumIter;
    unsigned SmallestCounterVal;
    LoopType Type;
  };

private:
  SnippyProgramContext &ProgContext;
  SnippyModule MainModule;

  std::unique_ptr<GlobalsPool> GP;

  mutable std::unique_ptr<IRegisterState> InitialMachineState;
  mutable std::unique_ptr<SimRunner> Runner;
  DenseMap<MemAddr, MemAddr> SelfcheckMap;
  bool HasTrackingMode = false;

  std::vector<Linker::SectionEntry> ExecutionPath;

  GeneratorSettings *GenSettings = nullptr;

  std::unique_ptr<TargetGenContextInterface> TargetContext;

  void initRunner() const;

  // Global - values before executing any code generated by snippy.
  std::map<MCRegister, MemAddr> SpilledRegsAddressesGlobal;
  // Local - values local to snippy code (tp's and gp's values might be
  // corrupted)
  std::map<MCRegister, MemAddr> SpilledRegsAddressesLocal;

  TopLevelMemoryAccessSampler MemAccSampler;

  size_t EntryPrologueInstrCnt = 0;
  size_t EntryEpilogueInstrCnt = 0;

  const MachineBasicBlock *RegsInitBlock = nullptr;

  DenseMap<const MachineBasicBlock *, LoopGenerationInfo> LoopInfoMap;

  std::optional<FloatSemanticsSamplerHolder> FloatOverwriteSamplers;

  void diagnoseSelfcheckSection(size_t MinSize) const;

  // A map that keeps SOME registers to value pairs for SOME blocks. This is
  // needed only in selfcheck mode and only for blocks which can be entered in
  // an order that doesn't match execution order.
  // Let's consider an example: we're generating a loop in selfcheck mode. Loops
  // in this mode have a special structure that is
  //        ...
  //         |
  //  +------v-----+
  //  |            |
  //  |  preheader |
  //  |            |
  //  +------+-----+
  //         |
  //         | --------------------------
  //         |/                          \
  //  +------v-----+                     |
  //  |            |                     |
  //  |   header   |                     |
  //  |            |                     |
  //  +------+-----+                     |
  //         |                           |
  //         |                           |
  //        ... (other loop body blocks) |
  //         |                           |
  //         |                           |
  //  +------v--------+                  |
  //  |               |                  |
  //  |    exiting    |                  |
  //  |               |                  |
  //  +------+-+------+   +-----------+  |
  //         | \          |           |  |
  //         |  ---------->   latch   |  |
  //  +------v-----+      |           |  |
  //  |            |      +-----+-----+  |
  //  |    exit    |            \        /
  //  |            |             --------
  //  +------------+
  //
  // Let's say that the loop has two iterations and conditional jump in exiting
  // block is `bne r1, r2, latch`. We have an agreement that in selfcheck mode
  // each iteration of the loop must do the same, difference might be only in
  // the stack as it's a supportive structure. Stack keeps actual values of
  // induction variables which for the loop above will be written to `r1`, `r2`
  // and compared(`bne`).
  //
  // Moving further with the example: at instructions generation stage we'll
  // visit blocks in the following order:
  //   preheader -> header -> other body blocks -> exiting -> latch -> exit.
  //
  // As you can see, we won't execute the second iteration of the loop. When
  // moving interpreter execution to exit block, we have the correct state of
  // registers/memory in interpreter except for r1 and r2 (as we execute only
  // one iteration). However, expected values of r1 and r2 are known statically
  // at loop latcher stage. So, we'll save these values in the map below and
  // write them in interpreter before executing the exit block.
  using RegToValueType = DenseMap<Register, APInt>;
  std::unordered_map<const MachineBasicBlock *, RegToValueType> IncomingValues;

  OpcodeToImmHistSequenceMap ImmHistMap;

  //       +---v---+
  //       |       |
  //       +---+---+
  //           | ______    ------------------------------
  //           |/      \
  //       +---v---+   |
  //       |       |   |      First consecutive loop
  //       +---+---+   |
  //           |\______/
  //           | ______    ------------------------------
  //           |/      \
  //       +---v---+   |
  //       |       |   |
  //       +---+---+   |
  //           |\______/
  //           | ______
  //           |/      \
  //       +---v---+   |
  //       |       |   |      Other consecutive loops
  //       +---+---+   |
  //           |\______/
  //           | ______
  //           |/      \
  //       +---v---+   |
  //       |       |   |
  //       +---+---+   |
  //           |\______/
  //           |           ------------------------------
  //           |
  //       +---v---+
  //       |       |
  //       +---+---+
  //
  // First loop header <-> Consecutive loops headers (basic blocks numbers)
  std::unordered_map<unsigned, std::set<unsigned>> ConsecutiveLoopsHeaders;

  std::size_t UtilitySectionFilledSize = 0;

public:
  GeneratorContext(SnippyProgramContext &ProgContext,
                   GeneratorSettings &GenSettings);
  ~GeneratorContext();

  const auto &getProgramContext() const { return ProgContext; }

  auto &getProgramContext() { return ProgContext; }

  auto getRegisterPool() { return getProgramContext().getRegisterPool(); }

  auto &getLLVMState() const { return getProgramContext().getLLVMState(); }

  auto &getLinker() { return getProgramContext().getLinker(); }
  const auto &getLinker() const { return getProgramContext().getLinker(); }

  auto &getMemoryAccessSampler() { return MemAccSampler; }

  void addToSelfcheckMap(MemAddr Address, MemAddr Distance) {
    [[maybe_unused]] auto EmplaceResult =
        SelfcheckMap.try_emplace(Address, Distance);
    assert(EmplaceResult.second &&
           "This address has been already inserted to map.");
  }

  bool hasSpillAddrsForReg(MCRegister Reg) const {
    return hasSpilledAddrLocal(Reg) && hasSpilledAddrGlobal(Reg);
  }

  const auto &getGlobalsPool() const { return *GP; }

  auto &getGlobalsPool() { return *GP; }

  auto &executionPath() const { return ExecutionPath; }

  void reserveSpillAddrsForReg(MCRegister Reg) {
    auto GlobalAddr = getNextAddrToSpill(Reg);
    addSpilledRegAddrGlobal(Reg, GlobalAddr);
    auto LocalAddr = getNextAddrToSpill(Reg);
    addSpilledRegAddrLocal(Reg, LocalAddr);
  }

  void addSpilledRegAddrGlobal(MCRegister Reg, MemAddr Addr) {
    auto [It, WasInserted] = SpilledRegsAddressesGlobal.emplace(Reg, Addr);
    assert(WasInserted &&
           "Attempt to add spill address twice for the same register");
  }

  MemAddr getSpilledRegAddrGlobal(MCRegister Reg) const {
    assert(SpilledRegsAddressesGlobal.count(Reg) &&
           "Attempt to get spill address for register that was not spilled");
    return SpilledRegsAddressesGlobal.at(Reg);
  }

  auto &getSpilledRegAddressesGlobal() const {
    return SpilledRegsAddressesGlobal;
  }

  bool hasSpilledAddrGlobal(MCRegister Reg) const {
    return SpilledRegsAddressesGlobal.count(Reg);
  }

  void addSpilledRegAddrLocal(MCRegister Reg, MemAddr Addr) {
    auto [It, WasInserted] = SpilledRegsAddressesLocal.emplace(Reg, Addr);
    assert(WasInserted &&
           "Attempt to add spill address twice for the same register");
  }

  MemAddr getSpilledRegAddrLocal(MCRegister Reg) const {
    assert(SpilledRegsAddressesLocal.count(Reg) &&
           "Attempt to get spill address for register that was not spilled");
    return SpilledRegsAddressesLocal.at(Reg);
  }

  auto &getSpilledRegAddressesLocal() const {
    return SpilledRegsAddressesLocal;
  }

  bool hasSpilledAddrLocal(MCRegister Reg) const {
    return SpilledRegsAddressesLocal.count(Reg);
  }

  void
  attachTargetContext(std::unique_ptr<TargetGenContextInterface> TgtContext);

  Interpreter &getOrCreateInterpreter() const;
  SimRunner &getOrCreateSimRunner() const;

  const IRegisterState &
  getInitialRegisterState(const TargetSubtargetInfo &Subtarget) const;
  StringRef getLastInstr() const {
    return GenSettings->InstrsGenerationConfig.LastInstr;
  }
  bool useRetAsLastInstr() const {
    return StringRef{"RET"}.equals_insensitive(
        GenSettings->InstrsGenerationConfig.LastInstr);
  }
  StringRef getABIName() const { return GenSettings->ABIName; }

  auto getRequestedInstrsNumForMainFunction() const {
    return GenSettings->InstrsGenerationConfig.NumInstrs.value_or(0);
  }

  bool isLoopGenerationPossible() const {
    assert(GenSettings);
    const auto &Branches = GenSettings->Cfg.Branches;
    const auto &Histogram = GenSettings->Cfg.Histogram;
    return Branches.LoopRatio > std::numeric_limits<double>::epsilon() &&
           Branches.PermuteCF && Branches.MaxDepth.Loop > 0 &&
           Histogram.hasCFInstrs(ProgContext.getOpcodeCache());
  }

  bool isInstrsNumKnown() const {
    return GenSettings->InstrsGenerationConfig.NumInstrs.has_value();
  }
  const BurstGramData &getBurstGram() const {
    return *GenSettings->Cfg.Burst.Data;
  }

  void notifyMemUpdate(uint64_t Addr, const APInt &Value) const;

  auto &getConfig() const {
    assert(GenSettings);
    return GenSettings->Cfg;
  }

  auto getNextFreeUtilityAddr() const {
    assert(ProgContext.hasUtilitySection());
    return ProgContext.getUtilitySection().VMA + UtilitySectionFilledSize;
  }

  auto addFilledUtilitySize(std::size_t NewFilled) {
    assert(ProgContext.hasUtilitySection());
    auto &UtilitySection = ProgContext.getUtilitySection();
    UtilitySectionFilledSize += NewFilled;
    if (UtilitySectionFilledSize > UtilitySection.Size) {
      LLVMContext Ctx;
      snippy::fatal(
          Ctx,
          "Section \"" + Twine(SectionsDescriptions::UtilitySectionName) +
              "\" is full (Size: " + Twine(UtilitySection.Size) +
              ", Filled Size: " + Twine(UtilitySectionFilledSize) + ")",
          "Try larger \"" + Twine(SectionsDescriptions::UtilitySectionName) +
              "\" section.");
    }
  }

  GenerationMode getGenerationMode() const {
    assert((!isApplyValuegramEachInstr() || isInstrsNumKnown()) &&
           "Initialization of registers before each instruction is supported "
           "only if a number of instructions are generated.");
    if (isApplyValuegramEachInstr())
      return GenerationMode::NumInstrs;
    if (!isInstrsNumKnown())
      return GenerationMode::Size;
    bool PCDistanceRequested = getConfig().Branches.isPCDistanceRequested();
    return PCDistanceRequested ? GenerationMode::Mixed
                               : GenerationMode::NumInstrs;
  }

  auto &getOpcodeToImmHistMap() const { return ImmHistMap; }

  auto &getSelfcheckSection() const {
    return ProgContext.getSelfcheckSection();
  }

  auto &getMemoryScheme() { return GenSettings->Cfg.MS; }
  const auto &getGenSettings() const {
    assert(GenSettings);
    return *GenSettings;
  }
  const auto &getCallGraphLayout() const { return GenSettings->Cfg.CGLayout; }

  template <typename It> size_t getCodeBlockSize(It Begin, It End) const {
    auto SizeAccumulator = [this](auto CurrSize, auto &MI) {
      size_t InstrSize =
          getLLVMState().getSnippyTarget().getInstrSize(MI, *this);
      if (InstrSize == 0)
        snippy::warn(
            WarningName::InstructionSizeUnknown,
            getProgramContext().getLLVMState().getCtx(),
            [&MI]() {
              std::string Ret;
              llvm::raw_string_ostream OS{Ret};
              OS << "Instruction '";
              MI.print(OS, /* IsStandalone */ true, /* SkipOpers */ true,
                       /* SkipDebugLoc */ true, /* AddNewLine */ false);
              OS << "' has unknown size";
              return Ret;
            }(),
            "function size estimation may be wrong");
      return CurrSize + InstrSize;
    };
    return std::accumulate(Begin, End, 0u, SizeAccumulator);
  }

  size_t getMBBSize(const MachineBasicBlock &MBB) const {
    return getCodeBlockSize(MBB.begin(), MBB.end());
  }

  size_t getFunctionSize(const MachineFunction &MF) const {
    return std::accumulate(MF.begin(), MF.end(), 0ul,
                           [this](auto CurrentSize, const auto &MBB) {
                             return CurrentSize + getMBBSize(MBB);
                           });
  }

  void addLoopGenerationInfoForMBB(const MachineBasicBlock *Header,
                                   LoopGenerationInfo LGI) {
    assert(Header);
    [[maybe_unused]] bool Inserted = LoopInfoMap.insert({Header, LGI}).second;
    assert(Inserted);
  }

  std::optional<LoopGenerationInfo>
  getLoopsGenerationInfoForMBB(const MachineBasicBlock *Header) {
    assert(Header);
    auto Found = LoopInfoMap.find(Header);
    return Found == LoopInfoMap.end() ? std::nullopt
                                      : std::optional(Found->second);
  }

  using OpcodeFilter = std::function<bool(unsigned)>;
  // FIXME: Those should be GeneratorContext's methods
  std::unique_ptr<DefaultOpcodeGenerator> createDefaultOpcodeGenerator() const {
    return GenSettings->Cfg.createDefaultOpcodeGenerator();
  }

  OpcGenHolder createCFOpcodeGenerator() const {
    return GenSettings->Cfg.createCFOpcodeGenerator(
        getProgramContext().getOpcodeCache());
  }

  OpcGenHolder
  createFlowOpcodeGenerator(OpcodeFilter OpcMask, bool MustHavePrimaryInstrs,
                            ArrayRef<OpcodeHistogramEntry> Overrides) const {
    return GenSettings->Cfg.createDFOpcodeGenerator(
        getProgramContext().getOpcodeCache(), OpcMask, Overrides,
        MustHavePrimaryInstrs);
  }

  auto getCFInstrsNum(size_t TotalInstructions) const {
    return GenSettings->Cfg.Histogram.getCFInstrsNum(
        TotalInstructions, getProgramContext().getOpcodeCache());
  }

  bool hasCallInstrs() const;

  bool hasCFInstrs() const {
    return GenSettings->Cfg.Histogram.hasCFInstrs(ProgContext.getOpcodeCache());
  }

  bool isApplyValuegramEachInstr() const {
    return GenSettings->Cfg.RegsHistograms.has_value();
  }

  StringRef getInitialRegYamlFile() const {
    return GenSettings->RegistersConfig.InitialRegYamlFile;
  }

  TargetGenContextInterface &getTargetContext() const { return *TargetContext; }

  auto &getMainModule() const { return MainModule; }

  auto &getMainModule() { return MainModule; }

  const TargetSubtargetInfo &getSubtargetImpl() const {
    auto &M = getMainModule().getModule();
    auto ModuleIt = M.begin();
    assert(ModuleIt != M.end() && "module must have at least one function");
    const Function &Fn = *ModuleIt;
    return *getLLVMState().getTargetMachine().getSubtargetImpl(Fn);
  }

  template <typename SubtargetType> const SubtargetType &getSubtarget() const {
    return static_cast<const SubtargetType &>(getSubtargetImpl());
  }

  void setEntryPrologueInstructionCount(size_t Count) {
    EntryPrologueInstrCnt = Count;
  }

  void setEntryEpilogueInstuctionCount(size_t Count) {
    EntryEpilogueInstrCnt = Count;
  }

  size_t getEntryPrologueInstructionCount() const {
    return EntryPrologueInstrCnt;
  }

  size_t getEntryEpilogueInstructionCount() const {
    return EntryEpilogueInstrCnt;
  }

  ArrayRef<MCRegister> getRegsSpilledToStack() const {
    return GenSettings->RegistersConfig.SpilledToStack;
  }

  ArrayRef<MCRegister> getRegsSpilledToMem() const {
    return GenSettings->RegistersConfig.SpilledToMem;
  }
  bool isRegSpilledToMem(MCRegister Reg) const {
    return llvm::is_contained(getRegsSpilledToMem(), Reg);
  }

  void checkMemStateAfterSelfcheck() const;

  void runSimulator(StringRef ImageToRun);

  bool hasTrackingMode() const { return HasTrackingMode; }
  bool hasExecutionTraceTrackingMode() const { return HasTrackingMode; }
  void disableTrackingMode() { HasTrackingMode = false; }

  bool hasModel() const {
    return !GenSettings->ModelPluginConfig.ModelLibraries.empty();
  }

  // See description for `IncomingValues`.
  void addIncomingValues(const MachineBasicBlock *MBB,
                         RegToValueType RegToValue);
  const RegToValueType &getIncomingValues(const MachineBasicBlock *MBB);

  bool isFirstConsecutiveLoopHeader(unsigned BB) const {
    return ConsecutiveLoopsHeaders.count(BB);
  }

  bool isNonFirstConsecutiveLoopHeader(unsigned BB) const {
    return any_of(make_second_range(ConsecutiveLoopsHeaders),
                  [BB](const auto &ConsLoops) { return ConsLoops.count(BB); });
  }

  void registerConsecutiveLoopsHeader(unsigned ConsecutiveLoopHeader,
                                      unsigned FirstLoopHeader) {
    ConsecutiveLoopsHeaders[FirstLoopHeader].insert(ConsecutiveLoopHeader);
  }

  const auto &getConsecutiveLoops(unsigned FirstConsecutiveLoop) const {
    assert(isFirstConsecutiveLoopHeader(FirstConsecutiveLoop));
    return ConsecutiveLoopsHeaders.at(FirstConsecutiveLoop);
  }

  const auto &getConsecutiveLoops() const { return ConsecutiveLoopsHeaders; }

  MemAddr getNextAddrToSpill(MCRegister Reg) {
    auto &State = ProgContext.getLLVMState();
    auto &Tgt = State.getSnippyTarget();
    auto RegSize = Tgt.getRegBitWidth(Reg, *this) / CHAR_BIT;
    assert(ProgContext.hasUtilitySection() &&
           "Global register reservation is only available if either utility or "
           "stack section are provided");
    auto Addr = getNextFreeUtilityAddr();
    addFilledUtilitySize(RegSize);
    return Addr;
  }

  void setRegsInitBlock(const MachineBasicBlock *MBB) { RegsInitBlock = MBB; }

  bool isRegsInitBlock(const MachineBasicBlock *MBB) const {
    return RegsInitBlock == MBB;
  }

  // (FIXME): This should be moved to a less global context, when
  // GeneratorContext is finally split into more manageable pieces.
  IAPIntSampler &
  getOrCreateFloatOverwriteValueSampler(const fltSemantics &Semantics) {
    auto &FPUCfg = GenSettings->Cfg.FPUConfig;
    assert(FPUCfg && FPUCfg->Overwrite);
    assert(FloatOverwriteSamplers.has_value());
    auto SamplerRefOrErr = FloatOverwriteSamplers->getSamplerFor(Semantics);
    if (auto Err = SamplerRefOrErr.takeError())
      snippy::fatal(getLLVMState().getCtx(), "Internal error", std::move(Err));
    return *SamplerRefOrErr;
  }

  planning::GenPolicy createGenPolicy(const MachineBasicBlock &MBB) const;
};

} // namespace snippy
} // namespace llvm
